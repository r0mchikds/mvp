{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28ddcd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем основные библиотеки для работы с данными и Torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d46d3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка детерминированного поведения для воспроизводимости результатов\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eaefd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем тестовый датасет и обучающую выборку (rating-based sampling)\n",
    "# для последующего формирования ground truth\n",
    "df_test = pd.read_csv(\"data/df_test_ground_truth_rating_based.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "746645dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём словарь ground truth: реальные товары, \n",
    "# с которыми взаимодействовал пользователь\n",
    "ground_truth = df_test.groupby(\"user_id\")[\"item_id\"].apply(set).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae62c2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция Precision@K — средняя доля релевантных товаров среди top-K рекомендаций\n",
    "def precision_at_k(preds, ground_truth, k=10):\n",
    "    scores = []\n",
    "    for user, pred_items in preds.items():\n",
    "        if user not in ground_truth:\n",
    "            continue\n",
    "        gt_items = ground_truth[user]\n",
    "        hits = sum([1 for item in pred_items[:k] if item in gt_items])\n",
    "        scores.append(hits / k)\n",
    "    return round(np.mean(scores), 4)\n",
    "# Функция average precision для одного пользователя\n",
    "def apk(pred, actual, k=10):\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "    pred = pred[:k]\n",
    "    score, num_hits = 0.0, 0.0\n",
    "    for i, p in enumerate(pred):\n",
    "        if p in actual and p not in pred[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i + 1.0)\n",
    "    return score / min(len(actual), k)\n",
    "# Средняя average precision по всем пользователям\n",
    "def map_at_k(preds, ground_truth, k=10):\n",
    "    return round(\n",
    "        np.mean([\n",
    "            apk(preds[u], ground_truth[u], k)\n",
    "            for u in preds if u in ground_truth\n",
    "        ]),\n",
    "        4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0272f650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем тренировочную выборку с CLIP-эмбеддингами (текст + изображение)\n",
    "df_train = pd.read_csv(\n",
    "    \"data/df_train_CLIP_rating_based.csv\",\n",
    "    na_values=[\"\"],  # исключаем \"Unknown\"\n",
    "    keep_default_na=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d530b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбираем CLIP-эмбеддинги (текст + изображение)\n",
    "item_vector_cols = [col for col in df_train.columns if col.startswith(\"clip_text_\") or col.startswith(\"clip_img_\")]\n",
    "user_ids = df_train[\"user_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67591d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Извлекаем CLIP-эмбеддинги\n",
    "clip_vectors  = df_train.drop_duplicates(\"item_id\")[[\"item_id\"] + item_vector_cols].set_index(\"item_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1eafdb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_vectors = clip_vectors.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be9c1b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clip_vectors shape: (67706, 200)\n",
      "item_vectors shape: (67706, 200)\n"
     ]
    }
   ],
   "source": [
    "print(\"clip_vectors shape:\", clip_vectors.shape)\n",
    "print(\"item_vectors shape:\", item_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2871a1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формируем вектор интересов пользователя как среднее по позитивным item-векторам\n",
    "user_vectors = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a518e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User vector aggregation: 100%|██████████| 551853/551853 [02:27<00:00, 3743.57it/s]\n"
     ]
    }
   ],
   "source": [
    "for user_id, group in tqdm(df_train[df_train[\"label\"] == 1].groupby(\"user_id\"), desc=\"User vector aggregation\", file=sys.stdout):\n",
    "    item_ids = group[\"item_id\"].values\n",
    "    vectors = item_vectors.loc[item_ids].values\n",
    "    user_vectors[user_id] = np.mean(vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "592aba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Строим датасет: конкатенируем векторы пользователя и товара\n",
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6203acb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building training pairs: 100%|██████████| 1635089/1635089 [01:18<00:00, 20901.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# Формируем обучающие пары\n",
    "for row in tqdm(df_train.itertuples(), total=len(df_train), desc=\"Building training pairs\", file=sys.stdout):\n",
    "    item_id = row.item_id\n",
    "    user_id = row.user_id\n",
    "    label = row.label\n",
    "\n",
    "    if user_id not in user_vectors or item_id not in item_vectors.index:\n",
    "        continue\n",
    "\n",
    "    user_vec = user_vectors[user_id]\n",
    "    item_vec = item_vectors.loc[item_id].values\n",
    "\n",
    "    concat_vec = np.concatenate([user_vec, item_vec])\n",
    "    X.append(concat_vec)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffaf96d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1542533, 400)\n",
      "y shape: (1542533,)\n"
     ]
    }
   ],
   "source": [
    "# Преобразуем списки в массивы для дальнейшей подачи в PyTorch\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2036a38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим пользовательский датасет\n",
    "# в него подаем раздельные вектора юзера и товара\n",
    "class MatchingDataset(Dataset):\n",
    "    def __init__(self, user_vecs, item_vecs, labels):\n",
    "        self.user_vecs = torch.tensor(user_vecs, dtype=torch.float32)\n",
    "        self.item_vecs = torch.tensor(item_vecs, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.user_vecs[idx], self.item_vecs[idx], self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efdb0989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сплит X на вектора юзера и товара\n",
    "user_dim = item_dim = X.shape[1] // 2\n",
    "X_user = X[:, :user_dim]\n",
    "X_item = X[:, user_dim:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2429185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "X_user_train, X_user_val, X_item_train, X_item_val, y_train_np, y_val_np = train_test_split(\n",
    "    X_user, X_item, y, test_size=0.1, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db6e1577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Учет дисбаланса классов\n",
    "n_pos = np.sum(y == 1)\n",
    "n_neg = np.sum(y == 0)\n",
    "pos_weight = (n_neg + n_pos) / (2 * n_pos)\n",
    "neg_weight = (n_neg + n_pos) / (2 * n_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4b4eefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MatchingDataset(X_user_train, X_item_train, y_train_np)\n",
    "val_dataset = MatchingDataset(X_user_val, X_item_val, y_val_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1658a527",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_config = {\n",
    "    \"init_scale\": [1.0, 2.0],\n",
    "    \"optimizer\": [\"Adam\", \"AdamW\", \"SGD\"],\n",
    "    \"learning_rate\": [1e-2, 1e-3, 1e-4],\n",
    "    \"loss_function\": [\"BCELoss\", \"FocalLoss\"],\n",
    "    \"weighting_strategy\": [\"none\", \"balanced\", \"sqrt-balanced\"],\n",
    "    \"batch_size\": [1024, 2048],\n",
    "    \"epochs\": [10, 20]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "949268ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерация всех конфигураций\n",
    "keys, values = zip(*grid_config.items())\n",
    "all_reduced_configs = [dict(zip(keys, v)) for v in itertools.product(*values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4fc0eeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random выбор 80 конфигураций\n",
    "random.seed(42)\n",
    "random_sample = random.sample(all_reduced_configs, 108) # 108 из 432 = 25% кейсов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41dc6235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df96ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем адаптированную функцию обучения под кастомную конфигурацию\n",
    "def create_train_model_fn(pos_weight, neg_weight, device):\n",
    "    def train_model(config):\n",
    "        # Формирование DataLoader с нужным batch_size\n",
    "        train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"])\n",
    "\n",
    "        # Инициализация модели CLIPCosineModel с init_scale\n",
    "        class CLIPCosineModel(nn.Module):\n",
    "            def __init__(self, init_scale):\n",
    "                super().__init__()\n",
    "                self.scale = nn.Parameter(torch.tensor(init_scale))\n",
    "\n",
    "            def forward(self, user_vec, item_vec):\n",
    "                user_norm = F.normalize(user_vec, p=2, dim=1)\n",
    "                item_norm = F.normalize(item_vec, p=2, dim=1)\n",
    "                cosine = (user_norm * item_norm).sum(dim=1, keepdim=True)\n",
    "                return torch.sigmoid(self.scale * cosine)\n",
    "\n",
    "        model = CLIPCosineModel(config[\"init_scale\"]).to(device)\n",
    "\n",
    "        # Выбор функции потерь\n",
    "        if config[\"loss_function\"] == \"BCELoss\":\n",
    "            criterion = nn.BCELoss(reduction=\"none\")\n",
    "        elif config[\"loss_function\"] == \"BCEWithLogitsLoss\":\n",
    "            criterion = nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "        elif config[\"loss_function\"] == \"FocalLoss\":\n",
    "            def focal_loss(preds, labels, gamma=2.0):\n",
    "                eps = 1e-6\n",
    "                p_t = preds * labels + (1 - preds) * (1 - labels)\n",
    "                loss = -((1 - p_t) ** gamma) * torch.log(p_t + eps)\n",
    "                return loss\n",
    "            criterion = focal_loss\n",
    "\n",
    "        # Выбор оптимайзера\n",
    "        if config[\"optimizer\"] == \"Adam\":\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "        elif config[\"optimizer\"] == \"AdamW\":\n",
    "            optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"learning_rate\"])\n",
    "        elif config[\"optimizer\"] == \"SGD\":\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=config[\"learning_rate\"])\n",
    "\n",
    "        # Обучение\n",
    "        for epoch in range(config[\"epochs\"]):\n",
    "            model.train()\n",
    "            train_losses = []\n",
    "            for u_vec, i_vec, labels in train_loader:\n",
    "                u_vec, i_vec, labels = u_vec.to(device), i_vec.to(device), labels.to(device).view(-1, 1)\n",
    "                preds = model(u_vec, i_vec)\n",
    "\n",
    "                if config[\"loss_function\"] == \"FocalLoss\":\n",
    "                    loss_raw = criterion(preds, labels)\n",
    "                else:\n",
    "                    loss_raw = criterion(preds, labels)\n",
    "\n",
    "                if config[\"weighting_strategy\"] == \"none\":\n",
    "                    weights = torch.ones_like(labels)\n",
    "                elif config[\"weighting_strategy\"] == \"balanced\":\n",
    "                    weights = torch.where(labels == 1, pos_weight, neg_weight).to(device)\n",
    "                elif config[\"weighting_strategy\"] == \"sqrt-balanced\":\n",
    "                    weights = torch.where(\n",
    "                        labels == 1,\n",
    "                        torch.sqrt(pos_weight),\n",
    "                        torch.sqrt(neg_weight)\n",
    "                    ).to(device)\n",
    "\n",
    "                loss = (loss_raw * weights).mean()\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_losses.append(loss.item())\n",
    "\n",
    "            # Валидация\n",
    "            model.eval()\n",
    "            val_losses, all_preds, all_targets = [], [], []\n",
    "            with torch.no_grad():\n",
    "                for u_vec, i_vec, labels in val_loader:\n",
    "                    u_vec, i_vec, labels = u_vec.to(device), i_vec.to(device), labels.to(device).view(-1, 1)\n",
    "                    preds = model(u_vec, i_vec)\n",
    "\n",
    "                    if config[\"loss_function\"] == \"FocalLoss\":\n",
    "                        loss_raw = criterion(preds, labels)\n",
    "                    else:\n",
    "                        loss_raw = criterion(preds, labels)\n",
    "\n",
    "                    if config[\"weighting_strategy\"] == \"none\":\n",
    "                        weights = torch.ones_like(labels)\n",
    "                    elif config[\"weighting_strategy\"] == \"balanced\":\n",
    "                        weights = torch.where(labels == 1, pos_weight, neg_weight).to(device)\n",
    "                    elif config[\"weighting_strategy\"] == \"sqrt-balanced\":\n",
    "                        weights = torch.where(\n",
    "                            labels == 1,\n",
    "                            torch.sqrt(pos_weight),\n",
    "                            torch.sqrt(neg_weight)\n",
    "                        ).to(device)\n",
    "\n",
    "                    loss = (loss_raw * weights).mean()\n",
    "                    val_losses.append(loss.item())\n",
    "                    all_preds.extend(preds.cpu().numpy())\n",
    "                    all_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "            # all_preds_bin = (np.array(all_preds) >= 0.5).astype(int)\n",
    "            # val_acc = accuracy_score(all_targets, all_preds_bin)\n",
    "            # tqdm.write(f\"Epoch {epoch + 1}/{config['epochs']} | \"\n",
    "            #            f\"Train Loss: {np.mean(train_losses):.4f} | \"\n",
    "            #            f\"Val Loss: {np.mean(val_losses):.4f} | \"\n",
    "            #            f\"Val Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "        return model\n",
    "\n",
    "    return train_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "965d23df",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c700ee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_fn = create_train_model_fn(\n",
    "    pos_weight=torch.tensor(pos_weight, dtype=torch.float32),\n",
    "    neg_weight=torch.tensor(neg_weight, dtype=torch.float32),\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "95935788",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b9b8add",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models: 100%|██████████| 108/108 [9:31:18<00:00, 317.40s/it] \n"
     ]
    }
   ],
   "source": [
    "for config in tqdm(random_sample, desc=\"Training models\"):\n",
    "    model = train_model_fn(config)\n",
    "    model.eval()\n",
    "    model_list.append((model, config, {}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0b5b094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготавливаем список кандидатов и их эмбеддинги для инференса\n",
    "candidate_items = item_vectors.index.tolist()\n",
    "candidate_vectors = item_vectors.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99013769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-N generation: 100%|██████████| 85083/85083 [54:10:38<00:00,  2.29s/it]   \n"
     ]
    }
   ],
   "source": [
    "# Формирование топов рекомендаций для каждого юзера\n",
    "for user_id in tqdm(ground_truth.keys(), desc=\"Top-N generation\", file=sys.stdout):\n",
    "    if user_id not in user_vectors:\n",
    "        continue\n",
    "    user_vec = user_vectors[user_id]\n",
    "    user_vec_batch = np.tile(user_vec, (candidate_vectors.shape[0], 1))\n",
    "    user_tensor = torch.tensor(user_vec_batch, dtype=torch.float32).to(device)\n",
    "    item_tensor = torch.tensor(candidate_vectors, dtype=torch.float32).to(device)\n",
    "\n",
    "    for idx, (model, config, predictions_dict) in enumerate(model_list):\n",
    "        with torch.no_grad():\n",
    "            scores = model(user_tensor, item_tensor).cpu().numpy().flatten()\n",
    "        sorted_items = np.array(candidate_items)[np.argsort(scores)[::-1]]\n",
    "        predictions_dict[user_id] = sorted_items[:10].tolist()\n",
    "        model_list[idx] = (model, config, predictions_dict)  # обновляем словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "078dfe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Храним все метрики\n",
    "metrics_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc026cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (model, config, predictions_dict) in enumerate(model_list):\n",
    "    precision = precision_at_k(predictions_dict, ground_truth)\n",
    "    map_score = map_at_k(predictions_dict, ground_truth)\n",
    "    metrics_list.append({\n",
    "        \"index\": idx,\n",
    "        \"precision@10\": precision,\n",
    "        \"map@10\": map_score,\n",
    "        \"config\": config\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b75bec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сортировка по Precision и MAP\n",
    "best_by_precision = max(metrics_list, key=lambda x: x[\"precision@10\"])\n",
    "best_by_map = max(metrics_list, key=lambda x: x[\"map@10\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87bd3380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model by Precision@10:\n",
      "Precision@10: 0.0032\n",
      "MAP@10:       0.008\n",
      "Config:\n",
      "{'init_scale': 2.0, 'optimizer': 'AdamW', 'learning_rate': 0.001, 'loss_function': 'FocalLoss', 'weighting_strategy': 'none', 'batch_size': 2048, 'epochs': 20}\n",
      "\n",
      "Best Model by MAP@10:\n",
      "Precision@10: 0.0032\n",
      "MAP@10:       0.0081\n",
      "Config:\n",
      "{'init_scale': 2.0, 'optimizer': 'SGD', 'learning_rate': 0.01, 'loss_function': 'FocalLoss', 'weighting_strategy': 'balanced', 'batch_size': 1024, 'epochs': 20}\n"
     ]
    }
   ],
   "source": [
    "# Вывод\n",
    "print(\"Best Model by Precision@10:\")\n",
    "print(f\"Precision@10: {best_by_precision['precision@10']}\")\n",
    "print(f\"MAP@10:       {best_by_precision['map@10']}\")\n",
    "print(\"Config:\")\n",
    "print(best_by_precision[\"config\"])\n",
    "\n",
    "if best_by_precision[\"index\"] != best_by_map[\"index\"]:\n",
    "    print(\"\\nBest Model by MAP@10:\")\n",
    "    print(f\"Precision@10: {best_by_map['precision@10']}\")\n",
    "    print(f\"MAP@10:       {best_by_map['map@10']}\")\n",
    "    print(\"Config:\")\n",
    "    print(best_by_map[\"config\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
