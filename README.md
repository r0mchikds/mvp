## MVP рекомендательной системы

Это **минимально жизнеспособная версия рекомендательной системы**, разработанная на базе **FastAPI**, **SQLModel**, **RabbitMQ** и **Streamlit**. Сервис поддерживает регистрацию и авторизацию пользователей, постановку задач на получение рекомендаций, обработку запросов через очередь и демонстрацию результатов через удобный UI.

---

### Что реализовано

1. **Спроектирована доменная модель** (пользователь, товар, взаимодействие, задача на рекомендацию);
2. **Обеспечено хранение данных** с помощью PostgreSQL;
3. **Разработан REST API** с авторизацией по JWT и маршрутизацией по ролям;
4. **Создан пользовательский интерфейс** на Streamlit, обеспечивающий базовую навигацию;
5. **Реализовано покрытие тестами**: API, модели, БД, очередь и обработка задач;
6. **Приложение упаковано в Docker** с многоконтейнерной архитектурой (`app`, `ml_worker`, `nginx`, `rabbitmq`, `db`, `streamlit_ui`);
7. **Обеспечена масштабируемость**: можно легко увеличить количество `ml_worker` для обработки задач в очереди;
8. **Данные и модель хранятся на Google Drive** и автоматически загружаются при старте приложения.

---

### Структура проекта

```
.
├── app/              # FastAPI-приложение (backend)
├── ml_worker/        # Воркеры обработки задач
├── streamlit_ui/     # Streamlit-интерфейс
├── nginx/            # Конфигурация nginx
├── docker-compose.yaml
└── README.md
```

---

### Как запустить

1. **Заполните `.env` в корне**, указав:

   ```dotenv
   DATA_FILE_ID=xxx
   MODEL_FILE_ID=xxx
   ```

2. **Запустите контейнеры:**

   ```bash
   docker-compose up --build
   ```

3. **Откройте в браузере:**

   * API-документация: [http://localhost:8080/docs](http://localhost:8080/docs)
   * Интерфейс Streamlit: [http://localhost:8501](http://localhost:8501)

---

### Тестирование

Для запуска тестов:

```bash
docker exec -it recs-api pytest -v
```

Работает с `SQLite in-memory` — данные не сохраняются между тестами.

---

### Возможности

* Авторизация и аутентификация пользователей;
* Асинхронная постановка задач в очередь RabbitMQ;
* Интеграция с ML-моделью через `ml_worker`;
* Хранение и обновление результата задачи в базе данных;
* Поддержка масштабирования количества воркеров;
* Простой UI для проверки гипотез и демонстрации;

---

### Примечания

* Модель и данные подтягиваются из Google Drive при старте контейнера;
* Воркеры можно масштабировать через параметр `replicas` в `docker-compose`;
* Финальная модель может быть легко подменена внутри `ml_worker`;
